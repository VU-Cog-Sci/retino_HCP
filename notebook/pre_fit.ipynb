{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop warnings\n",
    "# -------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# General imports\n",
    "# ---------------\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import ipdb\n",
    "import platform\n",
    "import numpy as np\n",
    "opj = os.path.join\n",
    "deb = ipdb.set_trace\n",
    "\n",
    "# MRI analysis imports\n",
    "# --------------------\n",
    "import nibabel as nb\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "with open('projects/retino_HCP/settings.json') as f:\n",
    "    json_s = f.read()\n",
    "    analysis_info = json.loads(json_s)\n",
    "\n",
    "with open('projects/retino_HCP/select_block.json') as f:\n",
    "    json_s = f.read()\n",
    "    select_block = json.loads(json_s)\n",
    "    \n",
    "trans_cmd = 'rsync -avuz --progress'\n",
    "\n",
    "# Define cluster/server specific parameters\n",
    "# -----------------------------------------\n",
    "if 'aeneas' in platform.uname()[1]:\n",
    "    base_dir = analysis_info['aeneas_base_folder'] \n",
    "elif 'lisa' in platform.uname()[1]:\n",
    "    base_dir = analysis_info['lisa_base_folder'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files in raw_data folder\n",
    "# ----------------------------\n",
    "for sub_name in analysis_info['subject_list'] :\n",
    "    sub_session = select_block[\"{sub}_sessions\".format(sub = sub_name)]\n",
    "    dest_folder = \"{base_dir}/raw_data/{sub}\".format(base_dir = base_dir, sub = sub_name)\n",
    "    try: os.makedirs(dest_folder)\n",
    "    except: pass\n",
    "      \n",
    "    for session in sub_session:\n",
    "        sub_session_run = select_block[\"{sub}_{ses}_run\".format(sub = sub_name, ses = session)]\n",
    "\n",
    "        for run in sub_session_run:\n",
    "            orig_folder = \"{base_dir}/derivatives/fmriprep/{sub}/{ses}/func\".format(base_dir = base_dir, sub = sub_name, ses=session)\n",
    "            \n",
    "            for hemi in ['L','R']:\n",
    "                orig_file = \"{orig_fold}/{sub}_{ses}_task-prf_{run}_space-fsaverage6_hemi-{hemi}.func.gii\".format(orig_fold = orig_folder, sub = sub_name, ses=session, run = run, hemi = hemi)\n",
    "                dest_file = \"{dest_fold}/{sub}_{ses}_task-prf_{run}_space-fsaverage6_hemi-{hemi}.func.gii\".format(dest_fold = dest_folder, sub = sub_name, ses=session, run = run, hemi = hemi)\n",
    "\n",
    "                os.system(\"{cmd} {orig} {dest}\".format(cmd = trans_cmd, orig = orig_file, dest = dest_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SG + PSC + AVG + COMBINE HEMI\n",
    "# -----------------------------\n",
    "for sub_name in analysis_info['subject_list'] :\n",
    "    \n",
    "    # SG + PSC\n",
    "    # --------\n",
    "    print(sub_name+': sg + psc')\n",
    "    file_list = sorted(glob.glob(\"{base_dir}/raw_data/{sub}/*func.gii\".format(base_dir = base_dir, sub = sub_name)))\n",
    "    for file in file_list:\n",
    "        print(file)\n",
    "        # load\n",
    "        pp_hemi = []\n",
    "        pp_hemi_file = nb.load(file)\n",
    "        pp_hemi.append(np.array([pp_hemi_file.darrays[i].data for i in range(len(pp_hemi_file.darrays))]))\n",
    "        pp_hemi = np.vstack(pp_hemi)\n",
    "\n",
    "        # sg filter\n",
    "        pp_hemi_filt = savgol_filter( x = pp_hemi.T,\n",
    "                                      window_length = analysis_info['sg_filt_window_length'],\n",
    "                                      polyorder = analysis_info['sg_filt_polyorder'],\n",
    "                                      deriv = analysis_info['sg_filt_deriv'],\n",
    "                                      axis = 1, \n",
    "                                      mode = 'nearest').T\n",
    "\n",
    "        pp_hemi_sg = pp_hemi - pp_hemi_filt + pp_hemi_filt.mean(axis=0)\n",
    "\n",
    "        # percent signal change\n",
    "        pp_hemi_sg_median = np.median(pp_hemi_sg, axis=0)\n",
    "        pp_hemi_sg_psc = 100.0 * (pp_hemi_sg - pp_hemi_sg_median)/pp_hemi_sg_median\n",
    "\n",
    "        # save\n",
    "        gii_out_name = file[:-4] + '_sg_psc.gii'\n",
    "        darrays_pp_hemi_sg_psc = [nb.gifti.gifti.GiftiDataArray(d) for d in pp_hemi_sg_psc]\n",
    "        gii_out = nb.gifti.gifti.GiftiImage(header = pp_hemi_file.header, \n",
    "                                            extra = pp_hemi_file.extra,\n",
    "                                            darrays = darrays_pp_hemi_sg_psc)\n",
    "\n",
    "        nb.save(img = gii_out,filename = gii_out_name)\n",
    "    \n",
    "    # AVERAGE RUNS\n",
    "    # ------------\n",
    "    print(sub_name+': average runs')\n",
    "    for hemi in ['L','R']:\n",
    "        file_list = sorted(glob.glob(\"{base_dir}/raw_data/{sub}/*{hemi}.func_sg_psc.gii\".format(base_dir = base_dir, sub = sub_name, hemi = hemi)))\n",
    "\n",
    "        pp_hemi_sg_psc_avg = np.zeros((120,40962))\n",
    "        for file in file_list:\n",
    "            print(file)\n",
    "            # load\n",
    "            pp_hemi_sg_psc = []\n",
    "            pp_hemi_sg_psc_file = nb.load(file)\n",
    "            pp_hemi_sg_psc.append(np.array([pp_hemi_sg_psc_file.darrays[i].data for i in range(len(pp_hemi_sg_psc_file.darrays))]))\n",
    "            pp_hemi_sg_psc = np.vstack(pp_hemi_sg_psc)\n",
    "\n",
    "            # avg\n",
    "            pp_hemi_sg_psc_avg += pp_hemi_sg_psc/len(file_list)\n",
    "\n",
    "        # save\n",
    "        gii_out_name = \"{base_dir}/raw_data/{sub}/{sub}_task-prf_space-fsaverage6_hemi-{hemi}.func_sg_psc.gii\".format(base_dir = base_dir, sub = sub_name, hemi = hemi)\n",
    "\n",
    "        darrays_pp_hemi_sg_psc_avg = [nb.gifti.gifti.GiftiDataArray(d) for d in pp_hemi_sg_psc_avg]\n",
    "        gii_out = nb.gifti.gifti.GiftiImage(header = pp_hemi_file.header,\n",
    "                                            extra = pp_hemi_file.extra,\n",
    "                                            darrays = darrays_pp_hemi_sg_psc_avg)\n",
    "\n",
    "        nb.save(img = gii_out,filename = gii_out_name)\n",
    "        \n",
    "    # COMBINE HEMISPHERE\n",
    "    # ------------------\n",
    "    print(sub_name+': combine hemisphere')\n",
    "    hemi_mat=[]\n",
    "    for hemi in ['L','R']:\n",
    "        # load\n",
    "        hemi_filename = \"{base_dir}/raw_data/{sub}/{sub}_task-prf_space-fsaverage6_hemi-{hemi}.func_sg_psc.gii\".format(base_dir = base_dir, sub = sub_name, hemi = hemi)\n",
    "        hemi_file = nb.load(hemi_filename)\n",
    "\n",
    "        # load\n",
    "        hemi_mat.append(np.array([hemi_file.darrays[i].data for i in range(len(hemi_file.darrays))]))\n",
    "\n",
    "    hemi_mat = np.hstack(hemi_mat)\n",
    "    \n",
    "    # save\n",
    "    gii_out_name = \"{base_dir}/raw_data/{sub}/{sub}_task-prf_space-fsaverage6.func_sg_psc.gii\".format(base_dir = base_dir, sub = sub_name)\n",
    "    darrays_hemi_mat = [nb.gifti.gifti.GiftiDataArray(d) for d in hemi_mat]\n",
    "    gii_out = nb.gifti.gifti.GiftiImage(header = hemi_file.header,\n",
    "                                        extra = hemi_file.extra,\n",
    "                                        darrays = darrays_hemi_mat)\n",
    "    \n",
    "    nb.save(img = gii_out,filename = gii_out_name)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
